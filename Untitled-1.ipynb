{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "from serpapi import GoogleSearch\n",
    "import datetime\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Ask about request needed\n",
    "words_toban = \"C,Go,JavaScript\"\n",
    "search_term = \"Data Analyst\"\n",
    "search_location = \"Geneva, Switzerland\"\n",
    "search_radius = 20\n",
    "results_number = 70\n",
    "api_key = \"sdd\" #open(\"../API keys/serpapi.txt\", \"r\").read()\n",
    "\n",
    "# Select only post of the day\n",
    "today_post = \"\"\n",
    "if today_post:\n",
    "    agreed = \"date_posted:today\"\n",
    "else:\n",
    "    agreed = \"\"\n",
    "\n",
    "# Select all techno to drop\n",
    "if words_toban == \"C,Go,JavaScript\" or words_toban == \"\":\n",
    "    banned_word = []\n",
    "else:\n",
    "    banned_word = words_toban.replace(\" \", \"\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(results_number\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m)):\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Look for next pages\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m         next_page_token \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserpapi_pagination\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_page_token\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m         next_page_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Scraping part\n",
    "for num in range(int(results_number/10)):\n",
    "\n",
    "    # Look for next pages\n",
    "    try:\n",
    "        next_page_token = results[\"serpapi_pagination\"]['next_page_token']\n",
    "    except KeyError:\n",
    "        next_page_token = \"\"\n",
    "\n",
    "    start = num\n",
    "    params = {\n",
    "        \"api_key\": api_key,\n",
    "        \"device\": \"desktop\",\n",
    "        \"engine\": \"google_jobs\",\n",
    "        \"google_domain\": \"google.com\",\n",
    "        \"q\": search_term,\n",
    "        #\"hl\": \"en\",\n",
    "        \"gl\": \"ch\",\n",
    "        \"lrad\": search_radius,\n",
    "        \"location\": search_location,\n",
    "        #\"chips\": agreed,\n",
    "        \"next_page_token\": next_page_token\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    \n",
    "    # check if the last search page (i.e., no results)\n",
    "    try:\n",
    "        if results[\"error\"] == \"Google hasn't returned any results for this query.\":\n",
    "            print(f\"{results[\"error\"]}\")\n",
    "            break\n",
    "    except KeyError:\n",
    "        print(f\"Getting SerpAPI data for page: {start}\")\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # create dataframe of 10 pulled results\n",
    "    jobs = results[\"jobs_results\"]\n",
    "    jobs = pd.DataFrame(jobs)\n",
    "    jobs = pd.concat(\n",
    "        [pd.DataFrame(jobs), pd.json_normalize(jobs[\"detected_extensions\"])], axis=1\n",
    "    )\n",
    "    jobs[\"date_time\"] = datetime.datetime.now(datetime.UTC).strftime(\n",
    "        \"%d-%m-%Y %H:%M\"\n",
    "    )  # Request time add\n",
    "\n",
    "    # concat dataframe\n",
    "    if start == 0:\n",
    "        jobs_all = jobs\n",
    "    else:\n",
    "        jobs_all = pd.concat([jobs_all, jobs])\n",
    "\n",
    "    jobs_all[\"search_term\"] = search_term\n",
    "    jobs_all[\"search_location\"] = search_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the useless columns\n",
    "to_drop = [\n",
    "    \"detected_extensions\",\n",
    "    \"extensions\",\n",
    "    \"apply_options\",\n",
    "    \"job_id\",\n",
    "    \"thumbnail\",\n",
    "    \"search_term\",\n",
    "    \"search_location\",\n",
    "]\n",
    "\n",
    "# Looking if every col exist and delete each of these\n",
    "for col in to_drop:\n",
    "    if col in jobs_all.columns:\n",
    "        jobs_all.drop(columns=[col], inplace=True)\n",
    "\n",
    "# Drop the duplicates offers\n",
    "jobs_all.drop_duplicates(subset=\"description\", inplace=True)\n",
    "\n",
    "\n",
    "# Drop offers with specifics words (technology)\n",
    "def find_words(sentence, words):\n",
    "    \"\"\"\n",
    "    Input : sentence and list of words banned\n",
    "    Output : True or False check\n",
    "    Do : normalize text and compare each word of the sentence with the words banned\n",
    "    \"\"\"\n",
    "    for word in words:\n",
    "        if word.lower() in sentence.lower():\n",
    "            return False\n",
    "            break\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "# Count of total rows (with banned_words filter)\n",
    "total_rows = jobs_all.shape[0]\n",
    "\n",
    "# Filter the offers with banned words, if banned_word list is not empty\n",
    "if banned_word != []:\n",
    "    jobs_all = jobs_all[jobs_all[\"description\"].apply(lambda a: find_words(a, banned_word))]\n",
    "\n",
    "# Count of filtred rows (without banned_words)\n",
    "rows_deleted = total_rows - jobs_all.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>share_link</th>\n",
       "      <th>description</th>\n",
       "      <th>schedule_type</th>\n",
       "      <th>posted_at</th>\n",
       "      <th>date_time</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Impact Data Analyst</td>\n",
       "      <td>Pictet</td>\n",
       "      <td>Genf</td>\n",
       "      <td>Impactful Careers</td>\n",
       "      <td>https://www.google.com/search?ibp=htl;jobs&amp;q=D...</td>\n",
       "      <td>We are seeking to recruit an Impact Data Analy...</td>\n",
       "      <td>Vollzeit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27-08-2024 10:39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global Data Analyst</td>\n",
       "      <td>Givaudan SA</td>\n",
       "      <td>Vernier</td>\n",
       "      <td>Join Givaudan</td>\n",
       "      <td>https://www.google.com/search?ibp=htl;jobs&amp;q=D...</td>\n",
       "      <td>Join us and celebrate the beauty of human expe...</td>\n",
       "      <td>Vollzeit</td>\n",
       "      <td>vor 12 Tagen</td>\n",
       "      <td>27-08-2024 10:39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title company_name location                via  \\\n",
       "0  Impact Data Analyst       Pictet     Genf  Impactful Careers   \n",
       "1  Global Data Analyst  Givaudan SA  Vernier      Join Givaudan   \n",
       "\n",
       "                                          share_link  \\\n",
       "0  https://www.google.com/search?ibp=htl;jobs&q=D...   \n",
       "1  https://www.google.com/search?ibp=htl;jobs&q=D...   \n",
       "\n",
       "                                         description schedule_type  \\\n",
       "0  We are seeking to recruit an Impact Data Analy...      Vollzeit   \n",
       "1  Join us and celebrate the beauty of human expe...      Vollzeit   \n",
       "\n",
       "      posted_at         date_time salary  \n",
       "0           NaN  27-08-2024 10:39    NaN  \n",
       "1  vor 12 Tagen  27-08-2024 10:39    NaN  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50 entries, 0 to 9\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   title          50 non-null     object\n",
      " 1   company_name   50 non-null     object\n",
      " 2   location       49 non-null     object\n",
      " 3   via            50 non-null     object\n",
      " 4   share_link     50 non-null     object\n",
      " 5   description    50 non-null     object\n",
      " 6   schedule_type  50 non-null     object\n",
      " 7   posted_at      22 non-null     object\n",
      " 8   date_time      50 non-null     object\n",
      " 9   salary         1 non-null      object\n",
      "dtypes: object(10)\n",
      "memory usage: 4.3+ KB\n"
     ]
    }
   ],
   "source": [
    "jobs_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'company_name', 'location', 'via', 'share_link', 'description',\n",
       "       'schedule_type', 'posted_at', 'date_time', 'salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = px.histogram(jobs_all, x=\"company_name\", color=\"via\")\n",
    "st.plotly_chart(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in jobs_all.columns:\n",
    "    px.histogram(jobs_all[col])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
